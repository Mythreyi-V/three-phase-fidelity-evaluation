{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install lime\n",
    "#!pip install shap\n",
    "#!pip install anchor-exp\n",
    "#!pip install hyperopt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from hyperopt import hp\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer, StandardScaler,MinMaxScaler\n",
    "\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action = 'ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib.pyplot import figure\n",
    "import matplotlib.image as mpimg\n",
    "import pylab as pl\n",
    "from pylab import savefig\n",
    "plt.style.use('seaborn-deep')\n",
    "\n",
    "import stability as st\n",
    "\n",
    "import statistics\n",
    "import scipy as scp\n",
    "import math\n",
    "\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "\n",
    "import shap\n",
    "\n",
    "from anchor import anchor_tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to project folder\n",
    "# please change to your own\n",
    "PATH = os.getcwd()\n",
    "\n",
    "dataset = \"bike_sharing\"\n",
    "balanced = True\n",
    "\n",
    "random_state = 39\n",
    "\n",
    "dataset_folder = \"%s/%s/\" % (PATH, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load and process data\n",
    "dataset_name = \"%s.csv\" % (dataset)\n",
    "dataset_path = dataset_folder + \"/datasets/\" + dataset_name\n",
    "data = pd.read_csv( dataset_path )\n",
    "\n",
    "# features\n",
    "class_cols = {\"diabetes\": \"Outcome\", \"breast_cancer\": \"diagnosis\", \"income\": \"income\",\n",
    "              \"housing\": \"MEDV\", \"student_scores\": \"G3\", \"bike_sharing\": \"total_rental\"}\n",
    "\n",
    "class_var = class_cols[dataset]\n",
    "\n",
    "rem_cols = {\"diabetes\": [class_var], \"breast_cancer\": [class_var, \"id\"], \"bike_sharing\": [class_var],\n",
    "           \"housing\": [class_var], \"student_scores\": [class_var], \"income\": [class_var, \"fnlwgt\"]}\n",
    "\n",
    "drop_cols = rem_cols[dataset]\n",
    "    \n",
    "feature_names = data.drop(drop_cols, axis=1).columns.to_list()\n",
    "\n",
    "# balance dataset\n",
    "if balanced == False:\n",
    "    classes = data[class_var]\n",
    "    neg_cases = data[data[class_var] == 0]\n",
    "    pos_cases = data[data[class_var] == 1]\n",
    "\n",
    "    if len(neg_cases) > len(pos_cases):\n",
    "        neg_cases = neg_cases.sample(n=len(pos_cases), random_state = random_state)\n",
    "    elif len(pos_cases) > len(neg_cases):\n",
    "        pos_cases = pos_cases.sample(n=len(neg_cases), random_state = random_state)\n",
    "\n",
    "    balanced_data = [neg_cases, pos_cases]\n",
    "    balanced_data = pd.concat(balanced_data)\n",
    "\n",
    "    # check how balanced the classes are\n",
    "    balanced_data.groupby(class_var).count()\n",
    "    \n",
    "else:\n",
    "    balanced_data = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = balanced_data[ feature_names ]#.values\n",
    "Y = balanced_data[class_var]#.values\n",
    "\n",
    "\n",
    "#generate training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=515)\n",
    "X_validation, X_test, y_validation, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=515)\n",
    "\n",
    "\n",
    "X_train.to_csv(dataset_path.replace(\".csv\", \"\") + \"_Xtrain.csv\", sep=\";\", index = False)\n",
    "X_test.to_csv(dataset_path.replace(\".csv\", \"\") + \"_Xtest.csv\", sep=\";\", index = False)\n",
    "X_validation.to_csv(dataset_path.replace(\".csv\", \"\") + \"_Xvalidation.csv\", sep=\";\", index = False)\n",
    "y_train.to_csv(dataset_path.replace(\".csv\", \"\") + \"_Ytrain.csv\", sep=\";\", index = False)\n",
    "y_test.to_csv(dataset_path.replace(\".csv\", \"\") + \"_Ytest.csv\", sep=\";\", index = False)\n",
    "y_validation.to_csv(dataset_path.replace(\".csv\", \"\") + \"_Yvalidation.csv\", sep=\";\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_template_test = pd.DataFrame(y_test)\n",
    "results_template_validation = pd.DataFrame(y_validation)\n",
    "results_template = pd.concat([results_template_test, results_template_validation])\n",
    "results_template = results_template.rename(columns = {class_var: \"Actual\"})\n",
    "\n",
    "results_template.to_csv(dataset_path.replace(\".csv\", \"\") + \"_results_template.csv\", sep=\";\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
