{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install lime\n",
    "#!pip install shap\n",
    "#!pip install anchor-exp\n",
    "#!pip install hyperopt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from hyperopt import hp\n",
    "import pickle\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "import sklearn\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-deep')\n",
    "\n",
    "import statistics\n",
    "import scipy as scp\n",
    "import math\n",
    "\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "\n",
    "import shap\n",
    "\n",
    "from anchor import anchor_tabular\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tree_features(cls, instance):\n",
    "    tree = cls.tree_\n",
    "    lvl = 0\n",
    "    left_child = tree.children_left[lvl]\n",
    "    right_child = tree.children_right[lvl]\n",
    "\n",
    "    feats = []\n",
    "    \n",
    "    while left_child != sklearn.tree._tree.TREE_LEAF and right_child != sklearn.tree._tree.TREE_LEAF:\n",
    "        feature = tree.feature[lvl]\n",
    "        feats.append(feature)\n",
    "        \n",
    "        if instance[feature] < tree.threshold[lvl]:\n",
    "            lvl = left_child\n",
    "        else:\n",
    "            lvl = right_child\n",
    "            \n",
    "        left_child = tree.children_left[lvl]\n",
    "        right_child = tree.children_right[lvl]\n",
    "            \n",
    "            \n",
    "    feats = set(feats)\n",
    "    \n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_path_depths(tree, feat_list, cur_depth = 0, lvl = 0, depths = []):\n",
    "\n",
    "    left_child = tree.children_left[lvl]\n",
    "    right_child = tree.children_right[lvl]\n",
    "    \n",
    "    if left_child == sklearn.tree._tree.TREE_LEAF:\n",
    "        depths.append(cur_depth)\n",
    "        \n",
    "    else:\n",
    "        depths = get_path_depths(tree, feat_list, cur_depth+1, left_child, depths)\n",
    "        depths = get_path_depths(tree, feat_list, cur_depth+1, right_child, depths)\n",
    "    return depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to project folder\n",
    "# please change to your own\n",
    "PATH = os.getcwd()\n",
    "\n",
    "dataset = \"breast_cancer\"\n",
    "cls_method = \"decision_tree\" \n",
    "classification = True\n",
    "\n",
    "random_state = 22\n",
    "exp_iter = 10\n",
    "\n",
    "save_to = \"%s/%s/\" % (PATH, dataset)\n",
    "dataset_folder = \"%s/datasets/\" % (save_to)\n",
    "final_folder = \"%s/%s/\" % (save_to, cls_method)\n",
    "\n",
    "#Get datasets\n",
    "X_train = pd.read_csv(dataset_folder+dataset+\"_Xtrain.csv\", index_col=False, sep = \";\")\n",
    "test_x = pd.read_csv(final_folder+\"test_sample.csv\", index_col=False, sep = \";\").values\n",
    "results = pd.read_csv(os.path.join(final_folder,\"results.csv\"), index_col=False, sep = \";\")\n",
    "\n",
    "feat_list = [each.replace(' ','_') for each in X_train.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = joblib.load(save_to+cls_method+\"/cls.joblib\")\n",
    "\n",
    "path_lengths = get_path_depths(cls.tree_, feat_list)\n",
    "num_retrieve = max(path_lengths)\n",
    "    \n",
    "if num_retrieve > len(feat_list):\n",
    "    num_retrieve = math.ceil(len(feat_list)*(2/3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_precision = []\n",
    "shap_recall = []\n",
    "\n",
    "if cls_method == \"xgboost\":\n",
    "    shap_explainer = shap.Explainer(cls)\n",
    "else:\n",
    "    shap_explainer = shap.Explainer(cls, X_train)\n",
    "\n",
    "for instance in test_x:\n",
    "    full_exp = [shap_explainer(instance, check_additivity = False).values for i in range(exp_iter)]\n",
    "    \n",
    "    if classification==True:\n",
    "        shap_exp = []\n",
    "        for each in full_exp:\n",
    "            single_exp = [feat[0] for feat in each]\n",
    "            shap_exp.append(single_exp)\n",
    "    else:\n",
    "        shap_exp = full_exp\n",
    "        \n",
    "    avg_val = np.average(shap_exp, axis = 0)\n",
    "    abs_val = [abs(val) for val in avg_val]\n",
    "    \n",
    "    if cls_method == \"decision_tree\":\n",
    "        feat_pos = get_tree_features(cls, instance)\n",
    "        true_features = [feat_list[i] for i in feat_pos]\n",
    "        true_features = set(true_features)\n",
    "    \n",
    "    #Get recall and precision for the average of shap values\n",
    "    bins = pd.cut(abs_val, 4, retbins = True, duplicates = \"drop\")\n",
    "    q1_min = bins[1][-2]\n",
    "\n",
    "    sorted_val = np.copy(abs_val)\n",
    "    sorted_val.sort()\n",
    "    path_min = sorted_val[-num_retrieve-1]\n",
    "    \n",
    "    shap_recall_features = set([feat_list[i] for i in range(len(feat_list)) if abs_val[i] > path_min])\n",
    "    shap_precision_features = set([feat_list[i] for i in range(len(feat_list)) if abs_val[i] > q1_min])\n",
    "    \n",
    "    recall = len(true_features.intersection(shap_recall_features))/len(true_features)\n",
    "    precision = len(true_features.intersection(shap_precision_features))/len(shap_precision_features)\n",
    "    \n",
    "    shap_precision.append(precision)\n",
    "    shap_recall.append(recall)\n",
    "    \n",
    "results[\"SHAP Precision\"] = shap_precision\n",
    "results[\"SHAP Recall\"] = shap_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(shap_precision))\n",
    "print(np.mean(shap_recall))\n",
    "\n",
    "print(np.mean(ind_shap_precision))\n",
    "print(np.mean(ind_shap_recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lime_recall = []\n",
    "lime_precision = []\n",
    "\n",
    "if classification==True:\n",
    "    class_names=['Negative','Positive']# negative is 0, positive is 1, 0 is left, 1 is right\n",
    "    lime_explainer = lime.lime_tabular.LimeTabularExplainer(X_train.values, feature_names = feat_list, \n",
    "                                                            class_names=class_names, discretize_continuous=True)\n",
    "else:\n",
    "    class_names = ['Final Value']\n",
    "    lime_explainer = lime.lime_tabular.LimeTabularExplainer(X_train.values, feature_names = feat_list, \n",
    "                                                            class_names=class_names, discretize_continuous=True, mode = \"regression\")\n",
    "\n",
    "for each in test_x:\n",
    "    lime_exp = []\n",
    "    for i in range(exp_iter):\n",
    "        if classification==True:\n",
    "            lime_exp.extend(lime_explainer.explain_instance(each, cls.predict_proba, \n",
    "                                                num_features=len(feat_list), labels=[0,1]).as_list())\n",
    "        else:\n",
    "            lime_exp.extend(lime_explainer.explain_instance(each, cls.predict, \n",
    "                                                num_features=len(feat_list), labels=[0,1]).as_list())\n",
    "            \n",
    "    weights = [[] for each in feat_list]\n",
    "    for exp in lime_exp:\n",
    "        feat = exp[0].replace(\"= \",'')\n",
    "        if '<' in feat:\n",
    "            parts = feat.split('<')\n",
    "        elif '>' in feat:\n",
    "            parts = feat.split('>')\n",
    "        \n",
    "        for part in parts:\n",
    "            if part.replace('.','').replace(' ','').isdigit()==False:\n",
    "                feat_name = part.replace(' ','')\n",
    "        n = feat_list.index(feat_name)\n",
    "        weights[n].append(exp[1])\n",
    "    \n",
    "    #ind_weights = [abs(feat[0]) for feat in weights]\n",
    "    weights = np.transpose(weights)\n",
    "    avg_weight = np.average(np.array(weights), axis = 0)\n",
    "    abs_weight = [abs(weight) for weight in avg_weight]\n",
    "    \n",
    "    if cls_method == \"decision_tree\":\n",
    "        feat_pos = get_tree_features(cls, each)\n",
    "        true_features = [feat_list[i] for i in feat_pos]\n",
    "        true_features = set(true_features)  \n",
    "        \n",
    "    #For average explanation    \n",
    "    bins = pd.cut(abs_weight, 4, retbins = True, duplicates = \"drop\")\n",
    "    q1_min = bins[1][-2]\n",
    "    \n",
    "    sorted_weight = np.copy(abs_weight)\n",
    "    sorted_weight.sort()\n",
    "    path_min = sorted_weight[-num_retrieve-1]\n",
    "    \n",
    "    lime_recall_features = set([feat_list[i] for i in range(len(feat_list)) if abs_weight[i] >= path_min])\n",
    "    lime_precision_features = set([feat_list[i] for i in range(len(feat_list)) if abs_weight[i] >= q1_min])\n",
    "    \n",
    "    recall = len(true_features.intersection(lime_recall_features))/len(true_features)\n",
    "    precision = len(true_features.intersection(lime_precision_features))/len(lime_precision_features)\n",
    "\n",
    "    lime_recall.append(recall)\n",
    "    lime_precision.append(precision)\n",
    "        \n",
    "results[\"LIME Precision\"] = lime_precision\n",
    "results[\"LIME Recall\"] = lime_recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(lime_precision))\n",
    "print(np.mean(lime_recall))\n",
    "\n",
    "print(np.mean(ind_lime_precision))\n",
    "print(np.mean(ind_lime_recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(os.path.join(save_to, cls_method, \"results.csv\"), index = False, sep = \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
